import pandas as pd
import numpy as np
from sklearn.metrics import mean_absolute_error
from tensorflow import keras
from keras.layers import Activation, Dense, Dropout, LSTM
from keras.models import Sequential
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.layers import LSTM
from sklearn.model_selection import train_test_split
Training_link = r"C:\Users\sagprasad\Desktop\AI Forum data\AI Fluency - Competition Dataset\AI Fluency - Training Data.csv"
Testing_link = r"C:\Users\sagprasad\Desktop\AI Forum data\AI Fluency - Competition Dataset\AI Fluency - Testing Data.csv"
fields = ['Asset_ID','Count','Open','High','Low','Close','Volume','VWAP']
data = pd.read_csv(Training_link,usecols = fields)
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(data)
x_train = np.array(scaled_data)
model = Sequential()
model.add(LSTM(units=50, return_sequences = True, input_shape=(x_train.shape[1],1)))
model.add(Dropout(0.5))
model.add(LSTM(units=50, return_sequences = True))
model.add(Dropout(0.5))
model.add(LSTM(units=50, return_sequences = True))
model.add(Dropout(0.5))
model.add(LSTM(units=50, return_sequences = True))
model.add(Dropout(0.5))
model.add(LSTM(units=50))
model.add(Dropout(0.5))
model.add(Dense(1))
fields = ['Target']
data = pd.read_csv(Training_link,usecols = fields)
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(data)
y_train = np.array(scaled_data)
np.set_printoptions(precision=17)
model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(x_train,y_train,epochs=1,batch_size=4032)
fields = ['Asset_ID','Count','Open','High','Low','Close','Volume','VWAP']
output_data = pd.read_csv(Testing_link, usecols = fields)
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(output_data)
output_data = np.array(scaled_data)
output_data= np.reshape(output_data,(output_data.shape[0],output_data.shape[1],1))
output_data.shape
output = model.predict(output_data)
output
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(data)
new_output = scaler.inverse_transform(output)
op = pd.DataFrame(new_output)
op.to_csv('USI_AI Fluency Day_Team Alpha_vFinal.csv')

